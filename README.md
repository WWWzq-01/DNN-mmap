Overview
- 背景：在处理大规模数据集时，一次性将所有数据加载到内存中可能会导致内存溢出。使用内存映射（mmap）技术，可以将文件直接映射到进程的地址空间，实现“按需”加载数据，从而有效降低内存占用。
- 核心目标: 实现一个基于mmap的数据加载器（Dataset/Dataloader），并将其应用到一个给定的DNN模型（如ResNet18）的训练流程中。
- 测试结果：对比使用mmap和不使用mmap两种方式在训练过程中的
  - 内存占用
  - 训练时间

---
实现
基于PyTorch实现即可。
可参考：

---
1. 查找基于PyTorch实现的DNN训练代码（如ResNet的训练代码）
  - 了解DNN训练流程，确定DNN训练加载数据特征的位置
2. Or 自主实现一个in-memory的DNN训练代码，记录该版本的内存使用和时间开销，作为baseline
3. 实现基于mmap的数据加载器，替换默认的数据加载器
4. 对比两个系统的内存开销和训练时间

---
交付
- 代码: 如 MmapDataset 的实现。
- 实验报告: 需要包含：
  - 实现思路: 简述 MmapDataset 的设计和实现原理。
  - 实验结果: 用图表清晰地展示使用mmap和不使用mmap在内存占用和训练时间上的对比。（比如mmap方式时间慢多少，内存节省多少）